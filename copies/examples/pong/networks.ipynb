{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classes to encapsulate the neuronal networks.\nTwo types of network capable of playing pong are implemented. PongNetRSTDP\ncan solve the problem by updating the weights of static synapses after\nevery simulation step according to the R-STDP rules defined in [1]_.\n\nPongNetDopa uses the actor-critic model described in [2]_ to determine the\namount of reward to send to the dopaminergic synapses between input and motor\nneurons. In this framework, the motor neurons represent the actor, while a\nsecondary network of three populations (termed striatum, VP, and dopaminergic\nneurons) form the critic which modulates dopamine concentration based on\ntemporal difference error.\n\nBoth of them inherit some functionality from the abstract base class PongNet.\n\n# See Also\n[Original implementation](https://github.com/electronicvisions/model-sw-pong)\n\n# References\n.. [1] Wunderlich T., et al (2019). Demonstrating advantages of\n       neuromorphic computation: a pilot study. Frontiers in neuroscience, 13,\n       260. https://doi.org/10.3389/fnins.2019.00260\n\n.. [2] Potjans W., Diesmann M.  and Morrison A. (2011). An imperfect\n       dopaminergic error signal can drive temporal-difference learning. PLoS\n       Computational Biology, 7(5), e1001133.\n       https://doi.org/10.1371/journal.pcbi.1001133\n\n:Authors: J Gille, T Wunderlich, Electronic Vision(s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nfrom abc import ABC, abstractmethod\nfrom copy import copy\n\nimport nest\nimport numpy as np\n\n# Simulation time per iteration in milliseconds.\nPOLL_TIME = 200\n# Number of spikes in an input spiketrain per iteration.\nN_INPUT_SPIKES = 20\n# Inter-spike interval of the input spiketrain.\nISI = 10.0\n# Standard deviation of Gaussian current noise in picoampere.\nBG_STD = 220.0\n# Reward to be applied depending on distance to target neuron.\nREWARDS_DICT = {0: 1.0, 1: 0.7, 2: 0.4, 3: 0.1}\n\n\nclass PongNet(ABC):\n    def __init__(self, apply_noise=True, num_neurons=20):\n        \"\"\"Abstract base class for network wrappers that learn to play pong.\n        Parts of the network that are required for both types of inheriting\n        class are created here. Namely, spike_generators and their connected\n        parrot_neurons, which serve as input, as well as iaf_psc_exp neurons\n        and their corresponding spike_recorders which serve as output. The\n        connection between input and output is not established here because it\n        is dependent on the plasticity rule used.\n\n        Args:\n            num_neurons (int, optional): Number of neurons in both the input and\n            output layer. Changes here need to be matched in the game\n            simulation in pong.py. Defaults to 20.\n            apply_noise (bool, optional): If True, Poisson noise is applied\n            to the motor neurons of the network. Defaults to True.\n        \"\"\"\n        self.apply_noise = apply_noise\n        self.num_neurons = num_neurons\n\n        self.weight_history = []\n        self.mean_reward = np.array([0.0 for _ in range(self.num_neurons)])\n        self.mean_reward_history = []\n        self.winning_neuron = 0\n\n        self.input_generators = nest.Create(\"spike_generator\", self.num_neurons)\n        self.input_neurons = nest.Create(\"parrot_neuron\", self.num_neurons)\n        nest.Connect(self.input_generators, self.input_neurons, {\"rule\": \"one_to_one\"})\n\n        self.motor_neurons = nest.Create(\"iaf_psc_exp\", self.num_neurons)\n        self.spike_recorders = nest.Create(\"spike_recorder\", self.num_neurons)\n        nest.Connect(self.motor_neurons, self.spike_recorders, {\"rule\": \"one_to_one\"})\n\n    def get_all_weights(self):\n        \"\"\"Returns all synaptic weights between input and motor neurons.\n\n        Returns:\n            numpy.array: 2D array of shape (n_neurons, n_neurons). Input\n            neurons are on the first axis, motor neurons on the second axis.\n        \"\"\"\n        x_offset = self.input_neurons[0].get(\"global_id\")\n        y_offset = self.motor_neurons[0].get(\"global_id\")\n        weight_matrix = np.zeros((self.num_neurons, self.num_neurons))\n        conns = nest.GetConnections(self.input_neurons, self.motor_neurons)\n        for conn in conns:\n            source, target, weight = conn.get([\"source\", \"target\", \"weight\"]).values()\n            weight_matrix[source - x_offset, target - y_offset] = weight\n\n        return weight_matrix\n\n    def set_all_weights(self, weights):\n        \"\"\"Sets synaptic weights between input and motor neurons of the network.\n\n        Args:\n            weights (numpy.array): 2D array of shape (n_neurons, n_neurons).\n            Input neurons are on the first axis, motor neurons on the second\n            axis. See get_all_weights().\n        \"\"\"\n        for i in range(self.num_neurons):\n            for j in range(self.num_neurons):\n                connection = nest.GetConnections(self.input_neurons[i], self.motor_neurons[j])\n                connection.set({\"weight\": weights[i, j]})\n\n    def get_spike_counts(self):\n        \"\"\"Returns the spike counts of all motor neurons from the\n        spike_recorders.\n\n        Returns:\n            numpy.array: Array of spike counts of all motor neurons.\n        \"\"\"\n        events = self.spike_recorders.get(\"n_events\")\n        return np.array(events)\n\n    def reset(self):\n        \"\"\"Resets the network for a new iteration by clearing all spike\n        recorders.\n        \"\"\"\n        self.spike_recorders.set({\"n_events\": 0})\n\n    def set_input_spiketrain(self, input_cell, biological_time):\n        \"\"\"Sets a spike train to the input neuron specified by an index.\n\n        Args:\n            input_cell (int): Index of the input neuron to be stimulated.\n            biological_time (float): Current biological time within the NEST\n            simulator (in ms).\n        \"\"\"\n        self.target_index = input_cell\n        self.input_train = [biological_time + self.input_t_offset + i * ISI for i in range(N_INPUT_SPIKES)]\n        # Round spike timings to 0.1ms to avoid conflicts with simulation time\n        self.input_train = [np.round(x, 1) for x in self.input_train]\n\n        # clear all input generators\n        for input_neuron in range(self.num_neurons):\n            nest.SetStatus(self.input_generators[input_neuron], {\"spike_times\": []})\n\n        nest.SetStatus(self.input_generators[input_cell], {\"spike_times\": self.input_train})\n\n    def get_max_activation(self):\n        \"\"\"Finds the motor neuron with the highest activation (number of spikes).\n\n        Returns:\n            int: Index of the motor neuron with the highest activation.\n        \"\"\"\n        spikes = self.get_spike_counts()\n        logging.debug(f\"Got spike counts: {spikes}\")\n\n        # If multiple neurons have the same activation, one is chosen at random\n        return int(np.random.choice(np.flatnonzero(spikes == spikes.max())))\n\n    def calculate_reward(self):\n        \"\"\"Calculates the reward to be applied to the network based on\n        performance in the previous simulation (distance between target and\n        actual output). For R-STDP this reward informs the learning rule,\n        for dopaminergic plasticity this is just a metric of fitness used for\n        plotting the simulation.\n\n        Returns:\n            float: Reward between 0 and 1.\n        \"\"\"\n        self.winning_neuron = self.get_max_activation()\n        distance = np.abs(self.winning_neuron - self.target_index)\n\n        if distance in REWARDS_DICT:\n            bare_reward = REWARDS_DICT[distance]\n        else:\n            bare_reward = 0\n\n        reward = bare_reward - self.mean_reward[self.target_index]\n\n        self.mean_reward[self.target_index] = float(self.mean_reward[self.target_index] + reward / 2.0)\n\n        logging.debug(f\"Applying reward: {reward}\")\n        logging.debug(f\"Average reward across all neurons: {np.mean(self.mean_reward)}\")\n\n        self.weight_history.append(self.get_all_weights())\n        self.mean_reward_history.append(copy(self.mean_reward))\n\n        return reward\n\n    def get_performance_data(self):\n        \"\"\"Retrieves the performance data of the network across all simulations.\n\n        Returns:\n            tuple: A Tuple of 2 numpy.arrays containing reward history and\n            weight history.\n        \"\"\"\n        return self.mean_reward_history, self.weight_history\n\n    @abstractmethod\n    def apply_synaptic_plasticity(self, biological_time):\n        \"\"\"Applies weight changes to the synapses according to a given learning\n        rule.\n\n        Args:\n            biological_time (float): Current NEST simulation time in ms.\n        \"\"\"\n        pass\n\n\nclass PongNetDopa(PongNet):\n    # Base reward current that is applied regardless of performance\n    baseline_reward = 100.0\n    # Maximum reward current to be applied to the dopaminergic neurons\n    max_reward = 1000\n    # Constant scaling factor for determining the current to be applied to the\n    # dopaminergic neurons\n    dopa_signal_factor = 4800\n    # Offset for input spikes at every iteration in milliseconds. This offset\n    # reserves the first part of every simulation step for the application of\n    # the dopaminergic reward signal, avoiding interference between it and the\n    # spikes caused by the input of the following iteration\n    input_t_offset = 32\n\n    # Neuron and synapse parameters:\n    # Initial mean weight for synapses between input- and motor neurons\n    mean_weight = 1275.0\n    # Standard deviation for starting weights\n    weight_std = 8\n    # Number of neurons per population in the critic-network\n    n_critic = 8\n    # Synaptic weights from striatum and VP to the dopaminergic neurons\n    w_da = -1150\n    # Synaptic weight between striatum and VP\n    w_str_vp = -250\n    # Synaptic delay for the direct connection between striatum and\n    # dopaminergic neurons\n    d_dir = 200\n    # Rate (Hz) for the background poisson generators\n    poisson_rate = 15\n\n    def __init__(self, apply_noise=True, num_neurons=20):\n        super().__init__(apply_noise, num_neurons)\n\n        self.vt = nest.Create(\"volume_transmitter\")\n        nest.SetDefaults(\n            \"stdp_dopamine_synapse\",\n            {\n                \"vt\": self.vt,\n                \"tau_c\": 70,\n                \"tau_n\": 30,\n                \"tau_plus\": 45,\n                \"Wmin\": 1220,\n                \"Wmax\": 1550,\n                \"b\": 0.028,\n                \"A_plus\": 0.85,\n            },\n        )\n\n        if apply_noise:\n            nest.Connect(\n                self.input_neurons,\n                self.motor_neurons,\n                {\"rule\": \"all_to_all\"},\n                {\n                    \"synapse_model\": \"stdp_dopamine_synapse\",\n                    \"weight\": nest.random.normal(self.mean_weight, self.weight_std),\n                },\n            )\n            self.poisson_noise = nest.Create(\"poisson_generator\", self.num_neurons, params={\"rate\": self.poisson_rate})\n            nest.Connect(self.poisson_noise, self.motor_neurons, {\"rule\": \"one_to_one\"}, {\"weight\": self.mean_weight})\n        else:\n            # Because the poisson_generators cause additional spikes in the\n            # motor neurons, it is necessary to compensate for their absence by\n            # slightly increasing the mean of the weights between input and\n            # motor neurons\n            nest.SetDefaults(\"stdp_dopamine_synapse\", {\"Wmax\": 1750})\n            nest.Connect(\n                self.input_neurons,\n                self.motor_neurons,\n                {\"rule\": \"all_to_all\"},\n                {\n                    \"synapse_model\": \"stdp_dopamine_synapse\",\n                    \"weight\": nest.random.normal(self.mean_weight * 1.3, self.weight_std),\n                },\n            )\n\n        # Setup the 'critic' as a network of three populations, consisting of\n        # the striatum, ventral pallidum (vp) and dopaminergic neurons (dopa)\n        self.striatum = nest.Create(\"iaf_psc_exp\", self.n_critic)\n        nest.Connect(\n            self.input_neurons,\n            self.striatum,\n            {\"rule\": \"all_to_all\"},\n            {\"synapse_model\": \"stdp_dopamine_synapse\", \"weight\": nest.random.normal(self.mean_weight, self.weight_std)},\n        )\n        self.vp = nest.Create(\"iaf_psc_exp\", self.n_critic)\n        nest.Connect(self.striatum, self.vp, syn_spec={\"weight\": self.w_str_vp})\n        self.dopa = nest.Create(\"iaf_psc_exp\", self.n_critic)\n        nest.Connect(self.vp, self.dopa, syn_spec={\"weight\": self.w_da})\n        nest.Connect(self.striatum, self.dopa, syn_spec={\"weight\": self.w_da, \"delay\": self.d_dir})\n        nest.Connect(self.dopa, self.vt)\n\n        # Current generator to stimulate dopaminergic neurons based on\n        # network performance\n        self.dopa_current = nest.Create(\"dc_generator\")\n        nest.Connect(self.dopa_current, self.dopa)\n\n    def apply_synaptic_plasticity(self, biological_time):\n        \"\"\"Injects a current into the dopaminergic neurons based on how much of\n        the motor neurons' activity stems from the target output neuron.\n        \"\"\"\n        spike_counts = self.get_spike_counts()\n        target_n_spikes = spike_counts[self.target_index]\n        # avoid zero division if none of the neurons fired.\n        total_n_spikes = max(sum(spike_counts), 1)\n\n        reward_current = self.dopa_signal_factor * target_n_spikes / total_n_spikes + self.baseline_reward\n\n        # Clip the dopaminergic signal to avoid runaway synaptic weights\n        reward_current = min(reward_current, self.max_reward)\n\n        self.dopa_current.stop = biological_time + self.input_t_offset\n        self.dopa_current.start = biological_time\n        self.dopa_current.amplitude = reward_current\n\n        self.calculate_reward()\n\n    def __repr__(self) -> str:\n        return (\"noisy \" if self.apply_noise else \"clean \") + \"TD\"\n\n\nclass PongNetRSTDP(PongNet):\n    # Offset for input spikes in every iteration in milliseconds\n    input_t_offset = 1\n    # Learning rate to use in weight updates\n    learning_rate = 0.7\n    # Amplitude of STDP curve in arbitrary units\n    stdp_amplitude = 36.0\n    # Time constant of STDP curve in milliseconds\n    stdp_tau = 64.0\n    # Satuation value for accumulated STDP\n    stdp_saturation = 128\n    # Initial mean weight for synapses between input- and motor neurons\n    mean_weight = 1300.0\n\n    def __init__(self, apply_noise=True, num_neurons=20):\n        super().__init__(apply_noise, num_neurons)\n\n        if apply_noise:\n            self.background_generator = nest.Create(\"noise_generator\", self.num_neurons, params={\"std\": BG_STD})\n            nest.Connect(self.background_generator, self.motor_neurons, {\"rule\": \"one_to_one\"})\n            nest.Connect(\n                self.input_neurons,\n                self.motor_neurons,\n                {\"rule\": \"all_to_all\"},\n                {\"weight\": nest.random.normal(self.mean_weight, 1)},\n            )\n        else:\n            # Because the noise_generators cause additional spikes in the motor\n            # neurons, it is necessary to compensate for their absence by\n            # slightly increasing the mean of the weights between input and\n            # motor neurons\n            nest.Connect(\n                self.input_neurons,\n                self.motor_neurons,\n                {\"rule\": \"all_to_all\"},\n                {\"weight\": nest.random.normal(self.mean_weight * 1.22, 5)},\n            )\n\n    def apply_synaptic_plasticity(self, biological_time):\n        \"\"\"Rewards network based on how close target and winning neuron are.\"\"\"\n        reward = self.calculate_reward()\n        self.apply_rstdp(reward)\n\n    def apply_rstdp(self, reward):\n        \"\"\"Applies the previously calculated reward to all relevant synapses\n        according to R-STDP principle.\n\n        Args:\n            reward (float): reward to be passed on to the synapses.\n        \"\"\"\n        # Store spike timings of all motor neurons\n        post_events = {}\n        offset = self.motor_neurons[0].get(\"global_id\")\n        for index, event in enumerate(self.spike_recorders.get(\"events\")):\n            post_events[offset + index] = event[\"times\"]\n\n        # Iterate over all connections from the stimulated neuron and change\n        # their weights dependent on spike time correlation and reward\n        for connection in nest.GetConnections(self.input_neurons[self.target_index]):\n            motor_neuron = connection.get(\"target\")\n            motor_spikes = post_events[motor_neuron]\n            correlation = self.calculate_stdp(self.input_train, motor_spikes)\n            old_weight = connection.get(\"weight\")\n            new_weight = old_weight + self.learning_rate * correlation * reward\n            connection.set({\"weight\": new_weight})\n\n    def calculate_stdp(self, pre_spikes, post_spikes, only_causal=True, next_neighbor=True):\n        \"\"\"Calculates the STDP trace for given spike trains.\n\n        Args:\n            pre_spikes (list, numpy.array): Presynaptic spike times in ms.\n            post_spikes (list, numpy.array): Postsynaptic spike times in ms.\n            only_causal (bool, optional): Use only facilitation and not\n            depression. Defaults to True.\n            next_neighbor (bool, optional): Use only next-neighbor\n            coincidences. Defaults to True.\n\n        Returns:\n            [float]: Scalar that corresponds to accumulated STDP trace.\n        \"\"\"\n\n        pre_spikes, post_spikes = np.sort(pre_spikes), np.sort(post_spikes)\n        facilitation = 0\n        depression = 0\n        positions = np.searchsorted(pre_spikes, post_spikes)\n        last_position = -1\n        for spike, position in zip(post_spikes, positions):\n            if position == last_position and next_neighbor:\n                continue  # Only next-neighbor pairs\n            if position > 0:\n                before_spike = pre_spikes[position - 1]\n                facilitation += self.stdp_amplitude * np.exp(-(spike - before_spike) / self.stdp_tau)\n            if position < len(pre_spikes):\n                after_spike = pre_spikes[position]\n                depression += self.stdp_amplitude * np.exp(-(after_spike - spike) / self.stdp_tau)\n            last_position = position\n        if only_causal:\n            return min(facilitation, self.stdp_saturation)\n        else:\n            return min(facilitation - depression, self.stdp_saturation)\n\n    def __repr__(self) -> str:\n        return (\"noisy \" if self.apply_noise else \"clean \") + \"R-STDP\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EBRAINS-23.09",
      "language": "python",
      "name": "ebrains-23.09"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}