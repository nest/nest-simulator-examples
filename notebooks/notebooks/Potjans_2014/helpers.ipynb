{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04dd31a",
   "metadata": {},
   "source": [
    "\n",
    "helpers.py\n",
    "\n",
    "This file is part of NEST.\n",
    "\n",
    "Copyright (C) 2004 The NEST Initiative\n",
    "\n",
    "NEST is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 2 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "NEST is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with NEST.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PyNEST Microcircuit: Helper Functions\n",
    "-------------------------------------------\n",
    "\n",
    "Helper functions for network construction, simulation and evaluation of the\n",
    "microcircuit.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e23e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd807ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DISPLAY\" not in os.environ:\n",
    "    import matplotlib\n",
    "\n",
    "    matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_synapses_from_conn_probs(conn_probs, popsize1, popsize2):\n",
    "    \"\"\"Computes the total number of synapses between two populations from\n",
    "    connection probabilities.\n",
    "\n",
    "    Here it is irrelevant which population is source and which target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn_probs\n",
    "        Matrix of connection probabilities.\n",
    "    popsize1\n",
    "        Size of first population.\n",
    "    popsize2\n",
    "        Size of second population.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_synapses\n",
    "        Matrix of synapse numbers.\n",
    "    \"\"\"\n",
    "    prod = np.outer(popsize1, popsize2)\n",
    "    num_synapses = np.log(1.0 - conn_probs) / np.log((prod - 1.0) / prod)\n",
    "    return num_synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postsynaptic_potential_to_current(C_m, tau_m, tau_syn):\n",
    "    r\"\"\"Computes a factor to convert postsynaptic potentials to currents.\n",
    "\n",
    "    The time course of the postsynaptic potential ``v`` is computed as\n",
    "    :math: `v(t)=(i*h)(t)`\n",
    "    with the exponential postsynaptic current\n",
    "    :math:`i(t)=J\\mathrm{e}^{-t/\\tau_\\mathrm{syn}}\\Theta (t)`,\n",
    "    the voltage impulse response\n",
    "    :math:`h(t)=\\frac{1}{\\tau_\\mathrm{m}}\\mathrm{e}^{-t/\\tau_\\mathrm{m}}\\Theta (t)`,\n",
    "    and\n",
    "    :math:`\\Theta(t)=1` if :math:`t\\geq 0` and zero otherwise.\n",
    "\n",
    "    The ``PSP`` is considered as the maximum of ``v``, i.e., it is\n",
    "    computed by setting the derivative of ``v(t)`` to zero.\n",
    "    The expression for the time point at which ``v`` reaches its maximum\n",
    "    can be found in Eq. 5 of [1]_.\n",
    "\n",
    "    The amplitude of the postsynaptic current ``J`` corresponds to the\n",
    "    synaptic weight ``PSC``.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Hanuschkin A, Kunkel S, Helias M, Morrison A and Diesmann M (2010)\n",
    "           A general and efficient method for incorporating precise spike times\n",
    "           in globally time-driven simulations.\n",
    "           Front. Neuroinform. 4:113.\n",
    "           DOI: `10.3389/fninf.2010.00113 <https://doi.org/10.3389/fninf.2010.00113>`__.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_m\n",
    "        Membrane capacitance (in pF).\n",
    "    tau_m\n",
    "        Membrane time constant (in ms).\n",
    "    tau_syn\n",
    "        Synaptic time constant (in ms).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PSC_over_PSP\n",
    "        Conversion factor to be multiplied to a `PSP` (in mV) to obtain a `PSC`\n",
    "        (in pA).\n",
    "\n",
    "    \"\"\"\n",
    "    sub = 1.0 / (tau_syn - tau_m)\n",
    "    pre = tau_m * tau_syn / C_m * sub\n",
    "    frac = (tau_m / tau_syn) ** sub\n",
    "\n",
    "    PSC_over_PSP = 1.0 / (pre * (frac**tau_m - frac**tau_syn))\n",
    "    return PSC_over_PSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a454f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_input_compensating_poisson(bg_rate, K_ext, tau_syn, PSC_ext):\n",
    "    \"\"\"Computes DC input if no Poisson input is provided to the microcircuit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bg_rate\n",
    "        Rate of external Poisson generators (in spikes/s).\n",
    "    K_ext\n",
    "        External indegrees.\n",
    "    tau_syn\n",
    "        Synaptic time constant (in ms).\n",
    "    PSC_ext\n",
    "        Weight of external connections (in pA).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DC\n",
    "        DC input (in pA) which compensates lacking Poisson input.\n",
    "    \"\"\"\n",
    "    DC = bg_rate * K_ext * PSC_ext * tau_syn * 0.001\n",
    "    return DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights_and_input_to_synapse_scaling(\n",
    "    full_num_neurons,\n",
    "    full_num_synapses,\n",
    "    K_scaling,\n",
    "    mean_PSC_matrix,\n",
    "    PSC_ext,\n",
    "    tau_syn,\n",
    "    full_mean_rates,\n",
    "    DC_amp,\n",
    "    poisson_input,\n",
    "    bg_rate,\n",
    "    K_ext,\n",
    "):\n",
    "    \"\"\"Adjusts weights and external input to scaling of indegrees.\n",
    "\n",
    "    The recurrent and external weights are adjusted to the scaling\n",
    "    of the indegrees. Extra DC input is added to compensate for the\n",
    "    scaling in order to preserve the mean and variance of the input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    full_num_neurons\n",
    "        Total numbers of neurons.\n",
    "    full_num_synapses\n",
    "        Total numbers of synapses.\n",
    "    K_scaling\n",
    "        Scaling factor for indegrees.\n",
    "    mean_PSC_matrix\n",
    "        Weight matrix (in pA).\n",
    "    PSC_ext\n",
    "        External weight (in pA).\n",
    "    tau_syn\n",
    "        Synaptic time constant (in ms).\n",
    "    full_mean_rates\n",
    "        Firing rates of the full network (in spikes/s).\n",
    "    DC_amp\n",
    "        DC input current (in pA).\n",
    "    poisson_input\n",
    "        True if Poisson input is used.\n",
    "    bg_rate\n",
    "        Firing rate of Poisson generators (in spikes/s).\n",
    "    K_ext\n",
    "        External indegrees.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PSC_matrix_new\n",
    "        Adjusted weight matrix (in pA).\n",
    "    PSC_ext_new\n",
    "        Adjusted external weight (in pA).\n",
    "    DC_amp_new\n",
    "        Adjusted DC input (in pA).\n",
    "\n",
    "    \"\"\"\n",
    "    PSC_matrix_new = mean_PSC_matrix / np.sqrt(K_scaling)\n",
    "    PSC_ext_new = PSC_ext / np.sqrt(K_scaling)\n",
    "\n",
    "    # recurrent input of full network\n",
    "    indegree_matrix = full_num_synapses / full_num_neurons[:, np.newaxis]\n",
    "    input_rec = np.sum(mean_PSC_matrix * indegree_matrix * full_mean_rates, axis=1)\n",
    "\n",
    "    DC_amp_new = DC_amp + 0.001 * tau_syn * (1.0 - np.sqrt(K_scaling)) * input_rec\n",
    "\n",
    "    if poisson_input:\n",
    "        input_ext = PSC_ext * K_ext * bg_rate\n",
    "        DC_amp_new += 0.001 * tau_syn * (1.0 - np.sqrt(K_scaling)) * input_ext\n",
    "    return PSC_matrix_new, PSC_ext_new, DC_amp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster(path, name, begin, end, N_scaling):\n",
    "    \"\"\"Creates a spike raster plot of the network activity.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    path\n",
    "        Path where the spike times are stored.\n",
    "    name\n",
    "        Name of the spike recorder.\n",
    "    begin\n",
    "        Time point (in ms) to start plotting spikes (included).\n",
    "    end\n",
    "        Time point (in ms) to stop plotting spikes (included).\n",
    "    N_scaling\n",
    "        Scaling factor for number of neurons.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    fs = 18  # fontsize\n",
    "    ylabels = [\"L2/3\", \"L4\", \"L5\", \"L6\"]\n",
    "    color_list = np.tile([\"#595289\", \"#af143c\"], 4)\n",
    "\n",
    "    sd_names, node_ids, data = __load_spike_times(path, name, begin, end)\n",
    "    last_node_id = node_ids[-1, -1]\n",
    "    mod_node_ids = np.abs(node_ids - last_node_id) + 1\n",
    "\n",
    "    label_pos = [(mod_node_ids[i, 0] + mod_node_ids[i + 1, 1]) / 2.0 for i in np.arange(0, 8, 2)]\n",
    "\n",
    "    stp = 1\n",
    "    if N_scaling > 0.1:\n",
    "        stp = int(10.0 * N_scaling)\n",
    "        print(\"  Only spikes of neurons in steps of {} are shown.\".format(stp))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, n in enumerate(sd_names):\n",
    "        times = data[i][\"time_ms\"]\n",
    "        neurons = np.abs(data[i][\"sender\"] - last_node_id) + 1\n",
    "        plt.plot(times[::stp], neurons[::stp], \".\", color=color_list[i])\n",
    "    plt.xlabel(\"time [ms]\", fontsize=fs)\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.yticks(label_pos, ylabels, fontsize=fs)\n",
    "    plt.savefig(os.path.join(path, \"raster_plot.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50babe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firing_rates(path, name, begin, end):\n",
    "    \"\"\"Computes mean and standard deviation of firing rates per population.\n",
    "\n",
    "    The firing rate of each neuron in each population is computed and stored\n",
    "    in a .dat file in the directory of the spike recorders. The mean firing\n",
    "    rate and its standard deviation are printed out for each population.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    path\n",
    "        Path where the spike times are stored.\n",
    "    name\n",
    "        Name of the spike recorder.\n",
    "    begin\n",
    "        Time point (in ms) to start calculating the firing rates (included).\n",
    "    end\n",
    "        Time point (in ms) to stop calculating the firing rates (included).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    sd_names, node_ids, data = __load_spike_times(path, name, begin, end)\n",
    "    all_mean_rates = []\n",
    "    all_std_rates = []\n",
    "    for i, n in enumerate(sd_names):\n",
    "        senders = data[i][\"sender\"]\n",
    "        # 1 more bin than node ids per population\n",
    "        bins = np.arange(node_ids[i, 0], node_ids[i, 1] + 2)\n",
    "        spike_count_per_neuron, _ = np.histogram(senders, bins=bins)\n",
    "        rate_per_neuron = spike_count_per_neuron * 1000.0 / (end - begin)\n",
    "        np.savetxt(os.path.join(path, (\"rate\" + str(i) + \".dat\")), rate_per_neuron)\n",
    "        # zeros are included\n",
    "        all_mean_rates.append(np.mean(rate_per_neuron))\n",
    "        all_std_rates.append(np.std(rate_per_neuron))\n",
    "    print(\"Mean rates: {} spikes/s\".format(np.around(all_mean_rates, decimals=3)))\n",
    "    print(\"Standard deviation of rates: {} spikes/s\".format(np.around(all_std_rates, decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(path, populations):\n",
    "    \"\"\"Creates a boxblot of the firing rates of all populations.\n",
    "\n",
    "    To create the boxplot, the firing rates of each neuron in each population\n",
    "    need to be computed with the function ``firing_rate()``.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    path\n",
    "        Path where the firing rates are stored.\n",
    "    populations\n",
    "        Names of neuronal populations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    fs = 18\n",
    "    pop_names = [string.replace(\"23\", \"2/3\") for string in populations]\n",
    "    label_pos = list(range(len(populations), 0, -1))\n",
    "    color_list = [\"#af143c\", \"#595289\"]\n",
    "    medianprops = dict(linestyle=\"-\", linewidth=2.5, color=\"black\")\n",
    "    meanprops = dict(linestyle=\"--\", linewidth=2.5, color=\"lightgray\")\n",
    "\n",
    "    rates_per_neuron_rev = []\n",
    "    for i in np.arange(len(populations))[::-1]:\n",
    "        rates_per_neuron_rev.append(np.loadtxt(os.path.join(path, (\"rate\" + str(i) + \".dat\"))))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bp = plt.boxplot(\n",
    "        rates_per_neuron_rev, 0, \"rs\", 0, medianprops=medianprops, meanprops=meanprops, meanline=True, showmeans=True\n",
    "    )\n",
    "    plt.setp(bp[\"boxes\"], color=\"black\")\n",
    "    plt.setp(bp[\"whiskers\"], color=\"black\")\n",
    "    plt.setp(bp[\"fliers\"], color=\"red\", marker=\"+\")\n",
    "\n",
    "    # boxcolors\n",
    "    for i in np.arange(len(populations)):\n",
    "        boxX = []\n",
    "        boxY = []\n",
    "        box = bp[\"boxes\"][i]\n",
    "        for j in list(range(5)):\n",
    "            boxX.append(box.get_xdata()[j])\n",
    "            boxY.append(box.get_ydata()[j])\n",
    "        boxCoords = list(zip(boxX, boxY))\n",
    "        k = i % 2\n",
    "        boxPolygon = Polygon(boxCoords, facecolor=color_list[k])\n",
    "        plt.gca().add_patch(boxPolygon)\n",
    "    plt.xlabel(\"firing rate [spikes/s]\", fontsize=fs)\n",
    "    plt.yticks(label_pos, pop_names, fontsize=fs)\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.savefig(os.path.join(path, \"box_plot.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __gather_metadata(path, name):\n",
    "    \"\"\"Reads names and ids of spike recorders and first and last ids of\n",
    "    neurons in each population.\n",
    "\n",
    "    If the simulation was run on several threads or MPI-processes, one name per\n",
    "    spike recorder per MPI-process/thread is extracted.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    path\n",
    "        Path where the spike recorder files are stored.\n",
    "    name\n",
    "        Name of the spike recorder, typically ``spike_recorder``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sd_files\n",
    "        Names of all files written by spike recorders.\n",
    "    sd_names\n",
    "        Names of all spike recorders.\n",
    "    node_ids\n",
    "        Lowest and highest id of nodes in each population.\n",
    "\n",
    "    \"\"\"\n",
    "    # load filenames\n",
    "    sd_files = []\n",
    "    sd_names = []\n",
    "    for fn in sorted(os.listdir(path)):\n",
    "        if fn.startswith(name):\n",
    "            sd_files.append(fn)\n",
    "            # spike recorder name and its ID\n",
    "            fnsplit = \"-\".join(fn.split(\"-\")[:-1])\n",
    "            if fnsplit not in sd_names:\n",
    "                sd_names.append(fnsplit)\n",
    "\n",
    "    # load node IDs\n",
    "    node_idfile = open(path + \"population_nodeids.dat\", \"r\")\n",
    "    node_ids = []\n",
    "    for node_id in node_idfile:\n",
    "        node_ids.append(node_id.split())\n",
    "    node_ids = np.array(node_ids, dtype=\"i4\")\n",
    "    return sd_files, sd_names, node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be600031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_spike_times(path, name, begin, end):\n",
    "    \"\"\"Loads spike times of each spike recorder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path\n",
    "        Path where the files with the spike times are stored.\n",
    "    name\n",
    "        Name of the spike recorder.\n",
    "    begin\n",
    "        Time point (in ms) to start loading spike times (included).\n",
    "    end\n",
    "        Time point (in ms) to stop loading spike times (included).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data\n",
    "        Dictionary containing spike times in the interval from ``begin``\n",
    "        to ``end``.\n",
    "\n",
    "    \"\"\"\n",
    "    sd_files, sd_names, node_ids = __gather_metadata(path, name)\n",
    "    data = {}\n",
    "    dtype = {\"names\": (\"sender\", \"time_ms\"), \"formats\": (\"i4\", \"f8\")}  # as in header\n",
    "    for i, name in enumerate(sd_names):\n",
    "        data_i_raw = np.array([[]], dtype=dtype)\n",
    "        for j, f in enumerate(sd_files):\n",
    "            if name in f:\n",
    "                # skip header while loading\n",
    "                ld = np.loadtxt(os.path.join(path, f), skiprows=3, dtype=dtype)\n",
    "                data_i_raw = np.append(data_i_raw, ld)\n",
    "\n",
    "        data_i_raw = np.sort(data_i_raw, order=\"time_ms\")\n",
    "        # begin and end are included if they exist\n",
    "        low = np.searchsorted(data_i_raw[\"time_ms\"], v=begin, side=\"left\")\n",
    "        high = np.searchsorted(data_i_raw[\"time_ms\"], v=end, side=\"right\")\n",
    "        data[i] = data_i_raw[low:high]\n",
    "    return sd_names, node_ids, data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "EBRAINS-24.04",
   "language": "python",
   "name": "ebrains-24.04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
