{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Supervised learning of a classification task with e-prop plasticity\n\n## Description\n\nThis script demonstrates supervised learning of a classification task with the eligibility propagation (e-prop)\nplasticity mechanism by Bellec et al. [1]_.\n\nThis type of learning is demonstrated at the proof-of-concept task in [1]_. We based this script on their\nTensorFlow script given in [2]_.\n\nThe task, a so-called evidence accumulation task, is inspired by behavioral tasks, where a lab animal (e.g., a\nmouse) runs along a track, gets cues on the left and right, and has to decide at the end of the track between\ntaking a left and a right turn of which one is correct. After a number of iterations, the animal is able to\ninfer the underlying rationale of the task. Here, the solution is to turn to the side in which more cues were\npresented.\n\n<img src=\"file://../../../../pynest/examples/eprop_plasticity/eprop_supervised_regression_infrastructure.png\" width=\"70 %\" alt=\"See Figure 1 below.\" align=\"center\">\n\nLearning in the neural network model is achieved by optimizing the connection weights with e-prop plasticity.\nThis plasticity rule requires a specific network architecture depicted in Figure 1. The neural network model\nconsists of a recurrent network that receives input from Poisson generators and projects onto two readout\nneurons - one for the left and one for the right turn at the end. The input neuron population consists of four\ngroups: one group providing background noise of a specific rate for some base activity throughout the\nexperiment, one group providing the input spikes of the left cues and one group providing them for the right\ncues, and a last group defining the recall window, in which the network has to decide. The readout neuron\ncompares the network signal $\\pi_k$ with the teacher target signal $\\pi_k^*$, which it receives from\na rate generator. Since the decision is at the end and all the cues are relevant, the network has to keep the\ncues in memory. Additional adaptive neurons in the network enable this memory.  The network's training error is\nassessed by employing a cross-entropy error loss.\n\nDetails on the event-based NEST implementation of e-prop can be found in [3]_.\n\n## References\n\n.. [1] Bellec G, Scherr F, Subramoney F, Hajek E, Salaj D, Legenstein R, Maass W (2020). A solution to the\n       learning dilemma for recurrent networks of spiking neurons. Nature Communications, 11:3625.\n       https://doi.org/10.1038/s41467-020-17236-y\n\n.. [2] https://github.com/IGITUGraz/eligibility_propagation/blob/master/Figure_3_and_S7_e_prop_tutorials/tutorial_evidence_accumulation_with_alif.py\n\n.. [3] Korcsak-Gorzo A, Stapmanns J, Espinoza Valverde JA, Dahmen D, van Albada SJ, Bolten M, Diesmann M.\n       Event-based implementation of eligibility propagation (in preparation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries\nWe begin by importing all libraries required for the simulation, analysis, and visualization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nest\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom cycler import cycler\nfrom IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schematic of network architecture\nThis figure, identical to the one in the description, shows the required network architecture in the center,\nthe input and output of the pattern generation task above, and lists of the required NEST device, neuron, and\nsynapse models below. The connections that must be established are numbered 1 to 7.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Image(filename=\"./eprop_supervised_classification_infrastructure.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize random generator\nWe seed the numpy random generator, which will generate random initial weights as well as random input and\noutput.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rng_seed = 1  # numpy random seed\nnp.random.seed(rng_seed)  # fix numpy random seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define timing of task\nThe task's temporal structure is then defined, once as time steps and once as durations in milliseconds.\nUsing a batch size larger than one aids the network in generalization, facilitating the solution to this task.\nThe original number of iterations requires distributed computing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_batch = 32  # batch size, 64 in reference [2], 32 in the README to reference [2]\nn_iter = 50  # number of iterations, 2000 in reference [2]\n\nn_input_symbols = 4  # number of input populations, e.g. 4 = left, right, recall, noise\nn_cues = 7  # number of cues given before decision\nprob_group = 0.3  # probability with which one input group is present\n\nsteps = {\n    \"cue\": 100,  # time steps in one cue presentation\n    \"spacing\": 50,  # time steps of break between two cues\n    \"bg_noise\": 1050,  # time steps of background noise\n    \"recall\": 150,  # time steps of recall\n    \"shift\": 4,  # time steps of shift - as generators & multimeter act on timesteps > 0 + signal travel time\n}\n\nsteps[\"cues\"] = n_cues * (steps[\"cue\"] + steps[\"spacing\"])  # time steps of all cues\nsteps[\"recall_onset\"] = steps[\"cues\"] + steps[\"bg_noise\"]  # time steps until recall onset\nsteps[\"sequence\"] = steps[\"recall_onset\"] + steps[\"recall\"]  # time steps of one full sequence\nsteps[\"task\"] = n_iter * n_batch * steps[\"sequence\"]  # time steps of task\nsteps[\"sim\"] = steps[\"task\"] + steps[\"shift\"]  # time steps of sim\n\nduration = {\"step\": 1.0}  # ms, temporal resolution of the simulation, only tested for 1 ms\n\nduration.update({key: value * duration[\"step\"] for key, value in steps.items()})  # ms, durations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up simulation\nAs last step of the setup, we reset the NEST kernel to remove all existing NEST simulation settings and\nobjects and set some NEST kernel parameters, some of which are e-prop-related.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_kernel = {\n    \"eprop_regression\": False,  # if True, regression; if False, classification\n    \"eprop_update_interval_reset\": True,  # if True, reset dynamic variables at start of each update interval\n    \"eprop_update_interval\": duration[\"sequence\"],  # ms, time interval for updating the synaptic weights\n    \"print_time\": True,  # if True, print time progress bar during simulation, set False if run as code cell\n    \"resolution\": duration[\"step\"],\n    \"total_num_virtual_procs\": 1,  # number of virtual processes, set in case of distributed computing\n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nest.ResetKernel()\nnest.SetKernelStatus(params_kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create neurons\nWe proceed by creating a certain number of input, recurrent, and readout neurons and setting their parameters.\nAdditionally, we already create an input spike generator and an output target rate generator, which we will\nconfigure later. Within the recurrent network, alongside a population of regular neurons, we introduce a\npopulation of adaptive neurons, to enhance the network's memory retention.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_in = 40  # number of input neurons\nn_ad = 50  # number of adaptive neurons\nn_reg = 50  # number of regular neurons\nn_rec = n_ad + n_reg  # number of recurrent neurons\nn_out = 2  # number of readout neurons\n\n\nparams_nrn_reg = {\n    \"C_m\": 1.0,  # pF, membrane capacitance - takes effect only if neurons get current input (here not the case)\n    \"gamma\": 0.3,  # scaling of the pseudo derivative\n    \"E_L\": 0.0,  # mV, leak reversal potential\n    \"I_e\": 0.0,  # pA, external current input\n    \"t_ref\": 5.0,  # ms, duration of refractory period\n    \"tau_m\": 20.0,  # ms, membrane time constant\n    \"V_m\": 0.0,  # mV, initial value of the membrane voltage\n    \"V_th\": 0.6,  # mV, spike threshold membrane voltage\n}\n\nparams_nrn_ad = {\n    \"adapt_tau\": 2000.0,  # ms, time constant of adaptive threshold\n    \"adaptation\": 0.0,  # initial value of the spike threshold adaptation\n    \"C_m\": 1.0,\n    \"E_L\": 0.0,\n    \"gamma\": 0.3,\n    \"I_e\": 0.0,\n    \"t_ref\": 5.0,\n    \"tau_m\": 20.0,\n    \"V_m\": 0.0,\n    \"V_th\": 0.6,\n}\n\nparams_nrn_ad[\"adapt_beta\"] = (\n    1.7 * (1.0 - np.exp(-1.0 / params_nrn_ad[\"adapt_tau\"])) / (1.0 - np.exp(-1.0 / params_nrn_ad[\"tau_m\"]))\n)  # prefactor of adaptive threshold\n\nparams_nrn_out = {\n    \"C_m\": 1.0,\n    \"E_L\": 0.0,\n    \"I_e\": 0.0,\n    \"start_learning\": duration[\"recall_onset\"],\n    \"tau_m\": 20.0,\n    \"V_m\": 0.0,\n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# intermediate parrot neurons required between input spike generators and recurrent neurons,\n# since devices cannot establish plastic synapses for technical reasons\n\ngen_spk_in = nest.Create(\"spike_generator\", n_in)\nnrns_in = nest.Create(\"parrot_neuron\", n_in)\nnrns_reg = nest.Create(\"eprop_iaf_psc_delta\", n_reg, params_nrn_reg)\nnrns_ad = nest.Create(\"eprop_iaf_psc_delta_adapt\", n_ad, params_nrn_ad)\nnrns_out = nest.Create(\"eprop_readout\", n_out, params_nrn_out)\ngen_rate_target = nest.Create(\"step_rate_generator\", n_out)\n\nnrns_rec = nrns_reg + nrns_ad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create recorders\nWe also create recorders, which, while not required for the training, will allow us to track various dynamic\nvariables of the neurons, spikes, and changes in synaptic weights. To save computing time and memory, the\nrecorders, the recorded variables, neurons, and synapses can be limited to the ones relevant to the\nexperiment, and the recording interval can be increased (see the documentation on the specific recorders). By\ndefault, recordings are stored in memory but can also be written to file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_record = 1  # number of adaptive and regular neurons each to record recordables from\nn_record_w = 3  # number of senders and targets to record weights from\n\nparams_mm_reg = {\"record_from\": [\"V_m\", \"V_m_pseudo_deriv\", \"learning_signal\"]}  # recordables\nparams_mm_ad = {\"record_from\": params_mm_reg[\"record_from\"] + [\"adapting_threshold\", \"adaptation\"]}\nparams_mm_out = {\"record_from\": [\"V_m\", \"readout_signal\", \"target_signal\", \"error_signal\"]}\n\nparams_wr = {\n    \"senders\": nrns_in[:n_record_w] + nrns_rec[:n_record_w],  # limit senders to subsample weights to record\n    \"targets\": nrns_rec[:n_record_w] + nrns_out,  # limit targets to subsample weights to record from\n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mm_reg = nest.Create(\"multimeter\", params_mm_reg)\nmm_ad = nest.Create(\"multimeter\", params_mm_ad)\nmm_out = nest.Create(\"multimeter\", params_mm_out)\nsr = nest.Create(\"spike_recorder\")\nwr = nest.Create(\"weight_recorder\", params_wr)\n\nnrns_reg_record = nrns_reg[:n_record]\nnrns_ad_record = nrns_ad[:n_record]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create connections\nNow, we define the connectivities and set up the synaptic parameters, with the synaptic weights drawn from\nnormal distributions. After these preparations, we establish the enumerated connections of the core network,\nas well as additional connections to the recorders.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_conn_all_to_all = {\"rule\": \"all_to_all\", \"allow_autapses\": False}\nparams_conn_one_to_one = {\"rule\": \"one_to_one\"}\n\n\ndef calculate_glorot_dist(fan_in, fan_out):\n    glorot_scale = 1.0 / max(1.0, (fan_in + fan_out) / 2.0)\n    glorot_limit = np.sqrt(3.0 * glorot_scale)\n    glorot_distribution = np.random.uniform(low=-glorot_limit, high=glorot_limit, size=(fan_in, fan_out))\n    return glorot_distribution\n\n\ndtype_weights = np.float32  # data type of weights - for reproducing TF results set to np.float32\nweights_in_rec = np.array(np.random.randn(n_in, n_rec).T / np.sqrt(n_in), dtype=dtype_weights)\nweights_rec_rec = np.array(np.random.randn(n_rec, n_rec).T / np.sqrt(n_rec), dtype=dtype_weights)\nnp.fill_diagonal(weights_rec_rec, 0.0)  # since no autapses set corresponding weights to zero\nweights_rec_out = np.array(calculate_glorot_dist(n_rec, n_out).T, dtype=dtype_weights)\nweights_out_rec = np.array(np.random.randn(n_rec, n_out), dtype=dtype_weights)\n\nparams_common_syn_eprop = {\n    \"adam\": True,  # if True, use Adam optimizer, if False gradient descent\n    \"adam_beta1\": 0.9,  # exponential decay rate for 1st moment estimate of Adam optimizeradam_beta1,\n    \"adam_beta2\": 0.999,  # exponential decay rate for 2nd moment raw estimate of Adam optimizer\n    \"adam_epsilon\": 1e-8,  # small numerical stabilization constant of Adam optimizer\n    \"batch_size\": n_batch,\n    \"recall_duration\": duration[\"recall\"],\n    \"weight_recorder\": wr,\n}\n\nparams_syn_in = {\n    \"synapse_model\": \"eprop_synapse\",\n    \"adam_m\": 0.0,  # initial 1st moment estimate m of Adam optimizer\n    \"adam_v\": 0.0,  # initial 2nd moment raw estimate v of Adam optimizer\n    \"c_reg\": 2.0,  # firing rate regularization scaling - double the TF c_reg for technical reasons\n    \"delay\": duration[\"step\"],  # ms, dendritic delay\n    \"eta\": 5e-3,  # learning rate\n    \"f_target\": 10.0,  # Hz, target firing rate for firing rate regularization\n    \"tau_m_out\": params_nrn_out[\"tau_m\"],  # ms, for technical reasons pass readout neuron membrane time constant\n    \"weight\": weights_in_rec,  # pA, initial values for the synaptic weights\n    \"Wmax\": 100.0,  # pA, maximal limit of the synaptic weights\n    \"Wmin\": -100.0,  # pA, minimal limit of the synaptic weights\n}\n\nparams_syn_rec = {\n    \"synapse_model\": \"eprop_synapse\",\n    \"adam_m\": 0.0,\n    \"adam_v\": 0.0,\n    \"c_reg\": 2.0,\n    \"delay\": duration[\"step\"],\n    \"eta\": 5e-3,\n    \"f_target\": 10.0,\n    \"tau_m_out\": params_nrn_out[\"tau_m\"],\n    \"weight\": weights_rec_rec,\n    \"Wmax\": 100.0,\n    \"Wmin\": -100.0,\n}\n\nparams_syn_out = {\n    \"synapse_model\": \"eprop_synapse\",\n    \"adam_m\": 0.0,\n    \"adam_v\": 0.0,\n    \"delay\": duration[\"step\"],\n    \"eta\": 5e-3,\n    \"tau_m_out\": params_nrn_out[\"tau_m\"],\n    \"weight\": weights_rec_out,\n    \"Wmax\": 100.0,\n    \"Wmin\": -100.0,\n}\n\nparams_syn_feedback = {\n    \"synapse_model\": \"eprop_learning_signal_connection\",\n    \"delay\": duration[\"step\"],\n    \"weight\": weights_out_rec,\n}\n\nparams_syn_out_out = {\n    \"synapse_model\": \"rate_connection_delayed\",\n    \"delay\": duration[\"step\"],\n    \"receptor_type\": 1,  # receptor type of readout neuron to receive other readout neuron's signals for softmax\n    \"weight\": 1.0,  # pA, weight 1.0 required for correct softmax computation for technical reasons\n}\n\nparams_syn_rate_target = {\n    \"synapse_model\": \"rate_connection_delayed\",\n    \"delay\": duration[\"step\"],\n    \"receptor_type\": 2,  # receptor type over which readout neuron receives target signal\n}\n\nparams_syn_static = {\n    \"synapse_model\": \"static_synapse\",\n    \"delay\": duration[\"step\"],\n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nest.SetDefaults(\"eprop_synapse\", params_common_syn_eprop)\n\nnest.Connect(gen_spk_in, nrns_in, params_conn_one_to_one, params_syn_static)  # connection 1\nnest.Connect(nrns_in, nrns_rec, params_conn_all_to_all, params_syn_in)  # connection 2\nnest.Connect(nrns_rec, nrns_rec, params_conn_all_to_all, params_syn_rec)  # connection 3\nnest.Connect(nrns_rec, nrns_out, params_conn_all_to_all, params_syn_out)  # connection 4\nnest.Connect(nrns_out, nrns_rec, params_conn_all_to_all, params_syn_feedback)  # connection 5\nnest.Connect(gen_rate_target, nrns_out, params_conn_one_to_one, params_syn_rate_target)  # connection 6\nnest.Connect(nrns_out, nrns_out, params_conn_all_to_all, params_syn_out_out)  # connection 7\n\nnest.Connect(nrns_in + nrns_rec, sr, params_conn_all_to_all, params_syn_static)\n\nnest.Connect(mm_reg, nrns_reg_record, params_conn_all_to_all, params_syn_static)\nnest.Connect(mm_ad, nrns_ad_record, params_conn_all_to_all, params_syn_static)\nnest.Connect(mm_out, nrns_out, params_conn_all_to_all, params_syn_static)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create input and output\nWe generate the input as four neuron populations, two producing the left and right cues, respectively, one the\nrecall signal and one the background input throughout the task. The sequence of cues is drawn with a\nprobability that favors one side. For each such sequence, the favored side, the solution or target, is\nassigned randomly to the left or right.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_evidence_accumulation_input_output(\n    n_batch, n_in, prob_group, input_spike_rate, n_cues, n_input_symbols, steps\n):\n    n_pop_nrn = n_in // n_input_symbols\n\n    prob_choices = np.array([prob_group, 1 - prob_group], dtype=np.float32)\n    idx = np.random.choice([0, 1], n_batch)\n    probs = np.zeros((n_batch, 2), dtype=np.float32)\n    probs[:, 0] = prob_choices[idx]\n    probs[:, 1] = prob_choices[1 - idx]\n\n    batched_cues = np.zeros((n_batch, n_cues), dtype=int)\n    for b_idx in range(n_batch):\n        batched_cues[b_idx, :] = np.random.choice([0, 1], n_cues, p=probs[b_idx])\n\n    input_spike_prob = np.zeros((n_batch, steps[\"sequence\"], n_in))\n\n    for b_idx in range(n_batch):\n        for c_idx in range(n_cues):\n            cue = batched_cues[b_idx, c_idx]\n\n            step_start = c_idx * (steps[\"cue\"] + steps[\"spacing\"]) + steps[\"spacing\"]\n            step_stop = step_start + steps[\"cue\"]\n\n            pop_nrn_start = cue * n_pop_nrn\n            pop_nrn_stop = pop_nrn_start + n_pop_nrn\n\n            input_spike_prob[b_idx, step_start:step_stop, pop_nrn_start:pop_nrn_stop] = input_spike_rate\n\n    input_spike_prob[:, -steps[\"recall\"] :, 2 * n_pop_nrn : 3 * n_pop_nrn] = input_spike_rate\n    input_spike_prob[:, :, 3 * n_pop_nrn :] = input_spike_rate / 4.0\n    input_spike_bools = input_spike_prob > np.random.rand(input_spike_prob.size).reshape(input_spike_prob.shape)\n    input_spike_bools[:, [0, -1], :] = 0  # remove spikes in first and last time step due to technical reasons\n\n    target_cues = np.zeros(n_batch, dtype=int)\n    target_cues[:] = np.sum(batched_cues, axis=1) > int(n_cues / 2)\n\n    return input_spike_bools, target_cues\n\n\ninput_spike_rate = 0.04  # kHz, firing rate of frozen input noise\ndtype_in_spks = np.float32  # data type of input spikes - for reproducing TF results set to np.float32\n\ninput_spike_bools_list = []\ntarget_cues_list = []\n\nfor iteration in range(n_iter):\n    input_spike_bools, target_cues = generate_evidence_accumulation_input_output(\n        n_batch, n_in, prob_group, input_spike_rate, n_cues, n_input_symbols, steps\n    )\n    input_spike_bools_list.append(input_spike_bools)\n    target_cues_list.extend(target_cues.tolist())\n\ninput_spike_bools_arr = np.array(input_spike_bools_list).reshape(steps[\"task\"], n_in)\ntimeline_task = np.arange(0, duration[\"task\"], duration[\"step\"])\n\nparams_gen_spk_in = [\n    {\"spike_times\": timeline_task[input_spike_bools_arr[:, nrn_in_idx]].astype(dtype_in_spks).tolist()}\n    for nrn_in_idx in range(n_in)\n]\n\ntarget_rate_changes = np.zeros((n_out, n_batch * n_iter))\ntarget_rate_changes[np.array(target_cues_list), np.arange(n_batch * n_iter)] = 1\n\nparams_gen_rate_target = [\n    {\n        # shift by one time step since NEST does not allow rate generation in 0th time step\n        \"amplitude_times\": (np.arange(0.0, duration[\"task\"], duration[\"sequence\"]) + duration[\"step\"]).tolist(),\n        \"amplitude_values\": target_rate_changes[nrn_out_idx].tolist(),\n    }\n    for nrn_out_idx in range(n_out)\n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nest.SetStatus(gen_spk_in, params_gen_spk_in)\nnest.SetStatus(gen_rate_target, params_gen_rate_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Force final update\nSynapses only get active, i.e., the correct weight update calculated and applied, when they transmit a spike.\nTo still be able to read out the correct weights at the end of the simulation, we force spiking of the\npresynaptic neuron and thus an update of all synapses, including those that have not transmitted a spike in\nthe last update interval, by sending a strong spike to all neurons that form the presynaptic side of an eprop\nsynapse. This step is required purely for technical reasons.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen_spk_final_update = nest.Create(\"spike_generator\", 1, {\"spike_times\": [duration[\"task\"] + 2]})\n\nnest.Connect(gen_spk_final_update, nrns_in + nrns_rec, \"all_to_all\", {\"weight\": 1000.0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read out pre-training weights\nBefore we begin training, we read out the initial weight matrices so that we can eventually compare them to\nthe optimized weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_weights(pop_pre, pop_post):\n    conns = nest.GetConnections(pop_pre, pop_post).get([\"source\", \"target\", \"weight\"])\n    conns[\"source\"] = np.array(conns[\"source\"]) - np.min(conns[\"source\"])\n    conns[\"target\"] = np.array(conns[\"target\"]) - np.min(conns[\"target\"])\n\n    weight_matrix = np.zeros((len(pop_post), len(pop_pre)))\n    weight_matrix[conns[\"target\"], conns[\"source\"]] = conns[\"weight\"]\n    return weight_matrix\n\n\nweights_pre_train = {\n    \"in_rec\": get_weights(nrns_in, nrns_rec),\n    \"rec_rec\": get_weights(nrns_rec, nrns_rec),\n    \"rec_out\": get_weights(nrns_rec, nrns_out),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate\nWe train the network by simulating for a set simulation time, determined by the number of iterations and the\nbatch size and the length of one sequence.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nest.Simulate(duration[\"sim\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read out post-training weights\nAfter the training, we can read out the optimized final weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weights_post_train = {\n    \"in_rec\": get_weights(nrns_in, nrns_rec),\n    \"rec_rec\": get_weights(nrns_rec, nrns_rec),\n    \"rec_out\": get_weights(nrns_rec, nrns_out),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read out recorders\nWe can also retrieve the recorded history of the dynamic variables and weights, as well as detected spikes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "events_mm_reg = mm_reg.get(\"events\")\nevents_mm_ad = mm_ad.get(\"events\")\nevents_mm_out = mm_out.get(\"events\")\nevents_sr = sr.get(\"events\")\nevents_wr = wr.get(\"events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate training error\nWe evaluate the network's training error by calculating a loss - in this case, the cross-entropy error between\nthe integrated recurrent network activity and the target rate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "readout_signal = events_mm_out[\"readout_signal\"]  # corresponds to softmax\ntarget_signal = events_mm_out[\"target_signal\"]\nsenders = events_mm_out[\"senders\"]\n\nreadout_signal = np.array([readout_signal[senders == i] for i in np.unique(senders)])\ntarget_signal = np.array([target_signal[senders == i] for i in np.unique(senders)])\n\n# align the signals for technical reasons\nreadout_signal = readout_signal[:, steps[\"shift\"] - 1 :]  # -1 since multimeter starts recording from 1\ntarget_signal = target_signal[:, steps[\"shift\"] - 2 : -1]  # extra -1 since target has shorter travel time\n\nreadout_signal = readout_signal.reshape(n_out, n_iter, n_batch, steps[\"sequence\"])[:, :, :, -steps[\"recall\"] :]\ntarget_signal = target_signal.reshape(n_out, n_iter, n_batch, steps[\"sequence\"])[:, :, :, -steps[\"recall\"] :]\n\nloss = -np.mean(np.sum(target_signal * np.log(readout_signal), axis=0), axis=(1, 2))\n\ny_prediction = np.argmax(np.mean(readout_signal, axis=3), axis=0)\ny_target = np.argmax(np.mean(target_signal, axis=3), axis=0)\naccuracy = np.mean((y_target == y_prediction), axis=1)\nrecall_errors = 1.0 - accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify results\nFurthermore, we compare the calculated losses to some hardcoded verification losses to ensure everything with\nthe NEST installation is fine. For the unmodified script, these should be precisely the same.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_verification = [\n    0.7411525500061912,\n    0.7403877948465877,\n    0.6657860139398386,\n    0.6637053390959563,\n    0.7294282459362229,\n]\n\nif loss.tolist()[:5] == loss_verification:\n    print(\"\\n verification successful \\n\")\nelse:\n    print(\"\\n verification FAILED ! \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\nThen, we plot a series of plots.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colors = {\n    \"blue\": \"#2854c5ff\",\n    \"red\": \"#e04b40ff\",\n    \"white\": \"#ffffffff\",\n}\n\nplt.rcParams.update(\n    {\n        \"font.sans-serif\": \"Arial\",\n        \"axes.spines.right\": False,\n        \"axes.spines.top\": False,\n        \"axes.prop_cycle\": cycler(color=[colors[\"blue\"], colors[\"red\"]]),\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot training error\nWe begin with two plots visualizing the training error of the network: the loss and the recall error, both\nplotted against the iterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 1, sharex=True)\n\naxs[0].plot(range(1, n_iter + 1), loss)\naxs[0].set_ylabel(r\"$E = -\\sum_{t,k} \\pi_k^{*,t} \\log \\pi_k^t$\")\n\naxs[1].plot(range(1, n_iter + 1), recall_errors)\naxs[1].set_ylabel(\"recall errors\")\n\naxs[-1].set_xlabel(\"training iteration\")\naxs[-1].set_xlim(1, n_iter)\naxs[-1].xaxis.get_major_locator().set_params(integer=True)\n\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot recordables\nThis plotting routine shows how to plot all of the recorded dynamic variables and spikes across time. We take\none snapshot in the first iteration and one snapshot at the end.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_recordable(ax, events, recordable, ylabel, xlims):\n    for sender in np.unique(events[\"senders\"]):\n        idc_sender = events[\"senders\"] == sender\n        idc_times = (events[\"times\"][idc_sender] > xlims[0]) & (events[\"times\"][idc_sender] < xlims[1])\n        ax.plot(events[\"times\"][idc_sender][idc_times], events[recordable][idc_sender][idc_times], lw=0.5)\n    ax.set_ylabel(ylabel)\n    margin = np.abs(np.max(events[recordable]) - np.min(events[recordable])) * 0.1\n    ax.set_ylim(np.min(events[recordable]) - margin, np.max(events[recordable]) + margin)\n\n\ndef plot_spikes(ax, events, nrns, ylabel, xlims):\n    idc_times = (events[\"times\"] > xlims[0]) & (events[\"times\"] < xlims[1])\n    idc_sender = np.isin(events[\"senders\"][idc_times], nrns.tolist())\n    senders_subset = events[\"senders\"][idc_times][idc_sender]\n    times_subset = events[\"times\"][idc_times][idc_sender]\n\n    ax.scatter(times_subset, senders_subset, s=0.1)\n    ax.set_ylabel(ylabel)\n    margin = np.abs(np.max(senders_subset) - np.min(senders_subset)) * 0.1\n    ax.set_ylim(np.min(senders_subset) - margin, np.max(senders_subset) + margin)\n\n\nfor xlims in [(0, steps[\"sequence\"]), (steps[\"task\"] - steps[\"sequence\"], steps[\"task\"])]:\n    fig, axs = plt.subplots(14, 1, sharex=True, figsize=(8, 14), gridspec_kw={\"hspace\": 0.4, \"left\": 0.2})\n\n    plot_spikes(axs[0], events_sr, nrns_in, r\"$z_i$\" + \"\\n\", xlims)\n    plot_spikes(axs[1], events_sr, nrns_reg, r\"$z_j$\" + \"\\n\", xlims)\n\n    plot_recordable(axs[2], events_mm_reg, \"V_m\", r\"$v_j$\" + \"\\n(mV)\", xlims)\n    plot_recordable(axs[3], events_mm_reg, \"V_m_pseudo_deriv\", r\"$\\psi_j$\" + \"\\n\", xlims)\n    plot_recordable(axs[4], events_mm_reg, \"learning_signal\", r\"$L_j$\" + \"\\n(pA)\", xlims)\n\n    plot_spikes(axs[5], events_sr, nrns_ad, r\"$z_j$\" \"\\n\", xlims)\n\n    plot_recordable(axs[6], events_mm_ad, \"V_m\", r\"$v_j$\" + \"\\n(mV)\", xlims)\n    plot_recordable(axs[7], events_mm_ad, \"V_m_pseudo_deriv\", r\"$\\psi_j$\" + \"\\n\", xlims)\n    plot_recordable(axs[8], events_mm_ad, \"adapting_threshold\", r\"$A_j$\" + \"\\n(mV)\", xlims)\n    plot_recordable(axs[9], events_mm_ad, \"learning_signal\", r\"$L_j$\" + \"\\n(pA)\", xlims)\n\n    plot_recordable(axs[10], events_mm_out, \"V_m\", r\"$v_k$\" + \"\\n(mV)\", xlims)\n    plot_recordable(axs[11], events_mm_out, \"target_signal\", r\"$\\pi^*_k$\" + \"\\n\", xlims)\n    plot_recordable(axs[12], events_mm_out, \"readout_signal\", r\"$\\pi_k$\" + \"\\n\", xlims)\n    plot_recordable(axs[13], events_mm_out, \"error_signal\", r\"$\\pi_k-\\pi^*_k$\" + \"\\n\", xlims)\n\n    axs[-1].set_xlabel(r\"$t$ (ms)\")\n    axs[-1].set_xlim(*xlims)\n\n    fig.align_ylabels()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot weight time courses\nSimilarly, we can plot the weight histories. Note that the weight recorder, attached to the synapses, works\ndifferently than the other recorders. Since synapses only get activated when they transmit a spike, the weight\nrecorder only records the weight in those moments. That is why the first weight registrations do not start in\nthe first time step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_weight_time_course(ax, events, nrns_senders, nrns_targets, ylabel):\n    for sender in nrns_senders.tolist():\n        for target in nrns_targets.tolist():\n            idc_syn = (events[\"senders\"] == sender) & (events[\"targets\"] == target)\n            ax.step(events[\"times\"][idc_syn], events[\"weights\"][idc_syn], c=colors[\"blue\"])\n        ax.set_ylabel(ylabel)\n        ax.set_ylim(-0.6, 0.6)\n\n\nfig, axs = plt.subplots(3, 1, sharex=True, figsize=(3, 4))\n\nplot_weight_time_course(axs[0], events_wr, nrns_in, nrns_rec, r\"$W_\\mathrm{in}$\" + \"\\n(pA)\")\nplot_weight_time_course(axs[1], events_wr, nrns_rec, nrns_rec, r\"$W_\\mathrm{rec}$\" + \"\\n(pA)\")\nplot_weight_time_course(axs[2], events_wr, nrns_rec, nrns_out, r\"$W_\\mathrm{out}$\" + \"\\n(pA)\")\n\naxs[-1].set_xlabel(r\"$t$ (ms)\")\naxs[-1].set_xlim(0, steps[\"task\"])\n\nfig.align_ylabels()\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot weight matrices\nIf one is not interested in the time course of the weights, it is possible to read out only the initial and\nfinal weights, which requires less computing time and memory than the weight recorder approach. Here, we plot\nthe corresponding weight matrices before and after the optimization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cmap = mpl.colors.LinearSegmentedColormap.from_list(\n    \"cmap\", ((0.0, colors[\"blue\"]), (0.5, colors[\"white\"]), (1.0, colors[\"red\"]))\n)\n\nfig, axs = plt.subplots(3, 2, sharex=\"col\", sharey=\"row\")\n\nall_w_extrema = [[[np.min(v), np.max(v)] for v in w.values()] for w in [weights_pre_train, weights_post_train]]\nargs = {\"cmap\": cmap, \"vmin\": np.min(all_w_extrema), \"vmax\": np.max(all_w_extrema)}\n\nfor i, weights in zip([0, 1], [weights_pre_train, weights_post_train]):\n    axs[0, i].pcolormesh(weights[\"in_rec\"].T, **args)\n    axs[1, i].pcolormesh(weights[\"rec_rec\"], **args)\n    cmesh = axs[2, i].pcolormesh(weights[\"rec_out\"], **args)\n\n    axs[2, i].set_xlabel(\"recurrent\\nneurons\")\n\naxs[0, 0].set_ylabel(\"input\\nneurons\")\naxs[1, 0].set_ylabel(\"recurrent\\nneurons\")\naxs[2, 0].set_ylabel(\"readout\\nneurons\")\nfig.align_ylabels(axs[:, 0])\n\naxs[0, 0].text(0.5, 1.1, \"pre-training\", transform=axs[0, 0].transAxes, ha=\"center\")\naxs[0, 1].text(0.5, 1.1, \"post-training\", transform=axs[0, 1].transAxes, ha=\"center\")\n\naxs[2, 0].yaxis.get_major_locator().set_params(integer=True)\n\ncbar = plt.colorbar(cmesh, cax=axs[1, 1].inset_axes([1.1, 0.2, 0.05, 0.8]), label=\"weight (pA)\")\n\nfig.tight_layout()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EBRAINS-23.06",
      "language": "python",
      "name": "ebrains-23.06"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
